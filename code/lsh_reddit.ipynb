{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5016851",
   "metadata": {},
   "source": [
    "# Spark: Duplicate Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "530742ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "import json\n",
    "import pyspark\n",
    "import hashlib\n",
    "import sys\n",
    "\n",
    "from pyspark import SparkConf, AccumulatorParam\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark import StorageLevel\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "path = 'a2_p2_Mittal_114855990_OUTPUT.txt'\n",
    "sys.stdout = open(path, 'w')\n",
    "\n",
    "session = SparkSession.builder\\\n",
    "            .appName(\"Assignment2\")\\\n",
    "            .config(\"spark.driver.memory\", \"15g\") \\\n",
    "            .config(\"spark.dynamicAllocation.enabled\", \"true\") \\\n",
    "            .config(\"spark.shuffle.service.enabled\", \"true\") \\\n",
    "            .config(\"spark.executor.cores\", \"4\") \\\n",
    "            .config(\"spark.rpc.message.maxSize\", \"256\") \\\n",
    "            .config(\"spark.executor.memory\", \"14g\") \\\n",
    "            .config(\"spark.executor.instances\", \"4\") \\\n",
    "            .getOrCreate()\n",
    "    \n",
    "sc = session.sparkContext\n",
    "# sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\n",
    "\n",
    "class SetAccum(AccumulatorParam):\n",
    "    def zero(self, zeroValue = set()):#overwrite this\n",
    "        return set()\n",
    "    def addInPlace(self, v1, v2):#overwrite this\n",
    "        v1.update(v2)\n",
    "        return v1\n",
    "SetAcc = sc.accumulator(set(), SetAccum())\n",
    "\n",
    "seeds = []\n",
    "for i in range(1000):\n",
    "    random.seed(i)\n",
    "    a = random.randint(0, 10000)\n",
    "    b = random.randint(0, 10000)\n",
    "    l = [a, b]\n",
    "    seeds.append(l)\n",
    "\n",
    "seedListSC = sc.broadcast(seeds)\n",
    "\n",
    "## Taken fron CHATGPT using PROMPT \"python code to create k-shingles of string\"\n",
    "def create_k_shingles(string, k):\n",
    "    \"\"\"\n",
    "    Creates k-shingles of a string.\n",
    "    \n",
    "    Parameters:\n",
    "    string (str): The input string.\n",
    "    k (int): The length of the shingles.\n",
    "    \n",
    "    Returns:\n",
    "    list: A list of k-shingles of the input string.\n",
    "    \"\"\"\n",
    "    shingles = set()\n",
    "    n = len(string)\n",
    "    p = n - k + 1\n",
    "    for i in range(0,p):\n",
    "        shingles.add(string[i:i+k])\n",
    "    SetAcc.add(shingles)\n",
    "    return shingles\n",
    "\n",
    "# dataRDD = sc.textFile('hdfs:/data/Appliances_5.json')\n",
    "filename = '../Project/Social-Listening-Dev/filtered_data/mental_health_sample.txt'\n",
    "dataRDD = sc.textFile(filename)\n",
    "dataRDD = dataRDD.map(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e79223f",
   "metadata": {},
   "source": [
    "Drop duplicate posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a4bc80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRDD = dataRDD.map(lambda x: (x[1], x[0])).reduceByKey(lambda x, y: x).map(lambda x: (x[1], x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b228043",
   "metadata": {},
   "source": [
    "Assign unique IDs to each post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a939d550",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRDD = dataRDD.zipWithUniqueId().map(lambda x: (x[1], x[0][0], x[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc125ba",
   "metadata": {},
   "source": [
    "Create shingles.\n",
    "\n",
    "\"\"\"\n",
    "We need to update k for shingle size.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39772e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shingledRDD = dataRDD.map(lambda x: (x[0], x[1], x[2], create_k_shingles(x[2], 4)))\n",
    "shingledRDD.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "shingledRDD.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1422f840",
   "metadata": {},
   "source": [
    "Get number of unique shingles and convert to a broadcasted variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "517e7f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_size = len(SetAcc.value)\n",
    "# print(len(SetAcc.value))\n",
    "hash_rangeSC = sc.broadcast(set_size)\n",
    "hashShingles = dict()\n",
    "for k, i in enumerate(SetAcc.value):\n",
    "    hf = k%len(seedListSC.value)\n",
    "    hashShingles[i] = (hf, (seedListSC.value[hf][0] * hash(i) + seedListSC.value[hf][1])%1001)\n",
    "    \n",
    "hashShinglesSC = sc.broadcast(hashShingles)\n",
    "num_bucketsSC = sc.broadcast(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc186730",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DictAccum(AccumulatorParam):\n",
    "    def zero(self, zeroValue = dict()):#overwrite this\n",
    "        return dict()\n",
    "    def addInPlace(self, v1, v2):#overwrite this\n",
    "        for i in v2.keys():\n",
    "            v1[i] = v2[i]\n",
    "        return v1\n",
    "DictAcc = sc.accumulator(dict(), DictAccum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5df29d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListAccum(AccumulatorParam):\n",
    "    def zero(self, zeroValue = []):#overwrite this\n",
    "        return []\n",
    "    def addInPlace(self, v1, v2):#overwrite this\n",
    "        return v1+v2\n",
    "\n",
    "listAcc = sc.accumulator([], ListAccum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ffebb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = sc.broadcast(10)\n",
    "bands = sc.broadcast(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e10be10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listRemoveInf(l):\n",
    "    ans  = []\n",
    "    for i, v in enumerate(l):\n",
    "        if v!= float('inf'):\n",
    "            ans.append(str(i)+\"$\"+str(v))\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77153d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddToBuckets(key, signatures):\n",
    "    allSetList = []\n",
    "    t = [hash('|'.join(listRemoveInf(signatures[i:i+rows.value])))%num_bucketsSC.value for i in range(0, 1000, rows.value)]\n",
    "    l = 0\n",
    "    for r in t:\n",
    "        if r == \"\":\n",
    "            continue\n",
    "        allSetList.append(str(l)+\"_\"+str(r)+\"_\"+str(key))\n",
    "        l+=rows.value\n",
    "    listAcc.add(allSetList)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d264042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minhash_signature_filtered(key, shingles):\n",
    "    try:\n",
    "        signature = [float('inf')] * len(seedListSC.value)\n",
    "        # hash_range = len(shingles)\n",
    "        for shingle in shingles:\n",
    "            hf = hashShinglesSC.value[shingle][0]\n",
    "            value = hashShinglesSC.value[shingle][1]\n",
    "            signature[hf] = min(signature[hf], value)\n",
    "        d = dict()\n",
    "        d[key] = shingles\n",
    "        DictAcc.add(d)\n",
    "        # print((key,signature))\n",
    "        AddToBuckets(key, signature)\n",
    "    except:\n",
    "        return None, None, None\n",
    "    return (key,signature,shingles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "433ae3e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[22] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filterList = shingledRDD.map(lambda x: x[0]).take(5)\n",
    "filterListSC = sc.broadcast(filterList)\n",
    "filterRDD = shingledRDD.filter(lambda x: x[0] in filterListSC.value).map(lambda x: (minhash_signature_filtered(x[0], x[3])))\n",
    "filterRDD.persist(StorageLevel.MEMORY_AND_DISK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c5cb871",
   "metadata": {},
   "outputs": [],
   "source": [
    "filterDict = sc.broadcast(DictAcc.value)\n",
    "selectedHashesSC = sc.broadcast(listAcc.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ab7110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSignatureFromSet_Unfiltered(key, shingles):\n",
    "    signature = [float('inf')] * len(seedListSC.value)\n",
    "    for shingle in shingles:\n",
    "        hf = hashShinglesSC.value[shingle][0]\n",
    "        value = hashShinglesSC.value[shingle][1]\n",
    "        signature[hf] = min(signature[hf], value)\n",
    "    return (key, signature, shingles)\n",
    "\n",
    "def calculateJaccard(k1,k2,m1,m2):\n",
    "    i = m1.intersection(m2)\n",
    "    u = m1.union(m2)\n",
    "    return (k1, float(len(i)/len(u)))\n",
    "\n",
    "def checkForCandidates(key, signatures, shingles):\n",
    "    t = [hash('|'.join(listRemoveInf(signatures[i:i+rows.value])))%num_bucketsSC.value for i in range(0, 1000, rows.value)]\n",
    "    l = 0\n",
    "    d = dict()\n",
    "    ans = []\n",
    "    for k in filterListSC.value:\n",
    "        d[k] = 0\n",
    "    for r in t:\n",
    "        if r == \"\":\n",
    "            continue\n",
    "        for k in filterListSC.value:\n",
    "            if d[k]==0:\n",
    "                if str(l)+\"_\"+str(r)+\"_\"+str(k) in selectedHashesSC.value:\n",
    "                    d[k]+=1\n",
    "            else:\n",
    "                continue   \n",
    "        l+=10\n",
    "    for k in filterListSC.value:\n",
    "        if d[k]>0:\n",
    "            h = calculateJaccard(k, key, filterDict.value[k], shingles)\n",
    "            if h[1]>=float(4/5):\n",
    "                ans.append(h)\n",
    "    return (key, ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "89a9bf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonFilteredRDD = shingledRDD.filter(lambda x: x[0] not in filterListSC.value).map(lambda x: createSignatureFromSet_Unfiltered(x[0], x[3]))\n",
    "selectedRDD = nonFilteredRDD.map(lambda x: checkForCandidates(x[0], x[1], x[2])).filter(lambda x: len(x[1]) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497e22b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
